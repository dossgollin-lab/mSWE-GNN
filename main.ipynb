{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from utils.visualization import *\n",
    "from utils.dataset import *\n",
    "from utils.miscellaneous import *\n",
    "from utils.load import *\n",
    "from utils.scaling import *\n",
    "from models.gnn import *\n",
    "from models.models import *\n",
    "from training.train import *\n",
    "from training.loss import *\n",
    "from database.graph_creation import *"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "# If you cannot reach the public wandb.ai (e.g. China), use the mirror:\n",
    "# os.environ[\"WANDB_BASE_URL\"] = \"https://api.bandw.top\"\n",
    "wandb.init()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot details"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['grid.color'] = 'k'\n",
    "mpl.rcParams['grid.linestyle'] = ':'\n",
    "mpl.rcParams['grid.linewidth'] = 0.5\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [7, 5]\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "mpl.rcParams['savefig.dpi'] = 300\n",
    "mpl.rcParams['savefig.bbox'] = 'tight'\n",
    "\n",
    "mpl.rcParams['font.size'] = 18\n",
    "mpl.rcParams['legend.fontsize'] = 'small'\n",
    "mpl.rcParams['figure.titlesize'] = 'small'\n",
    "\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "\n",
    "video_folder = figures_folder = 'results'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# wandb.login()\n",
    "\n",
    "# CHANGE THIS CONFIG FILE TO CHANGE THE EXPERIMENT\n",
    "cfg_file = \"config.yaml\"\n",
    "# cfg_file = \"config_finetune.yaml\"\n",
    "\n",
    "config = read_config(cfg_file)\n",
    "wandb.finish()\n",
    "wandb_logger = WandbLogger(log_model='all',\n",
    "                           mode='online',\n",
    "                           config=config,)\n",
    "\n",
    "# Keep the original config structure since wandb.config might flatten it\n",
    "# config = wandb.config"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "L.seed_everything(config['models']['seed'])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset_parameters = config['dataset_parameters']\n",
    "scalers = copy(config['scalers'])\n",
    "selected_node_features = config['selected_node_features']\n",
    "selected_edge_features = config['selected_edge_features']\n",
    "\n",
    "train_dataset, val_dataset, test_dataset, scalers = create_model_dataset(\n",
    "    scalers=scalers, device=device, \n",
    "    **dataset_parameters, **selected_node_features, **selected_edge_features\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "temporal_dataset_parameters = config['temporal_dataset_parameters']\n",
    "\n",
    "temporal_train_dataset = to_temporal_dataset(train_dataset, **temporal_dataset_parameters)\n",
    "\n",
    "print('Number of training simulations:\\t', len(train_dataset))\n",
    "print('Number of training samples:\\t', len(temporal_train_dataset))\n",
    "print('Number of node features:\\t', temporal_train_dataset[0].x.shape[-1])\n",
    "print('Number of rollout steps:\\t', temporal_train_dataset[0].y.shape[-1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "num_node_features, num_edge_features = temporal_train_dataset[0].x.size(-1), temporal_train_dataset[0].edge_attr.size(-1)\n",
    "num_nodes, num_edges = temporal_train_dataset[0].x.size(0), temporal_train_dataset[0].edge_attr.size(0)\n",
    "\n",
    "temporal_res = dataset_parameters['temporal_res']\n",
    "previous_t = temporal_dataset_parameters['previous_t']\n",
    "time_start = temporal_dataset_parameters['time_start']\n",
    "time_stop = temporal_dataset_parameters['time_stop']\n",
    "max_rollout_steps = temporal_dataset_parameters['rollout_steps']\n",
    "test_dataset_name = dataset_parameters['test_dataset_name']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model_parameters = copy(config['models'])\n",
    "model_type = model_parameters.pop('model_type')\n",
    "\n",
    "if model_type == 'MSGNN':\n",
    "    num_scales = train_dataset[0].mesh.num_meshes\n",
    "    model_parameters['num_scales'] = num_scales\n",
    "    \n",
    "model = get_model(model_type)(\n",
    "    num_node_features=num_node_features,\n",
    "    num_edge_features=num_edge_features,\n",
    "    previous_t=previous_t,\n",
    "    device=device,\n",
    "    **model_parameters).to(device)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "source": [
    "trainer_options = copy(config['trainer_options'])\n",
    "\n",
    "lr_info = config['lr_info']\n",
    "\n",
    "# info for testing dataset\n",
    "temporal_test_dataset_parameters = get_temporal_test_dataset_parameters(\n",
    "    config, temporal_dataset_parameters)\n",
    "\n",
    "temporal_val_dataset = to_temporal_dataset(val_dataset, rollout_steps=-1, **temporal_test_dataset_parameters)\n",
    "\n",
    "plmodule = LightningTrainer(model, lr_info, trainer_options, temporal_test_dataset_parameters).to(device)\n",
    "\n",
    "pldatamodule = DataModule(temporal_train_dataset, temporal_val_dataset, \n",
    "                          batch_size=trainer_options['batch_size'])\n",
    "\n",
    "print(\"Total number of paramters:\", sum(p.numel() for p in model.parameters()))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Define callbacks\n",
    "checkpoint_callback = ModelCheckpoint(dirpath='lightning_logs/models',\n",
    "                                      monitor=\"val_loss\", mode='min',\n",
    "                                      save_top_k=1)\n",
    "curriculum_callback = CurriculumLearning(max_rollout_steps, patience=5)\n",
    "early_stopping      = EarlyStopping('val_CSI_005', mode='max', patience=trainer_options['patience'])\n",
    "batch_size_finder   = CurriculumBatchSizeFinder(max_rollout_steps, init_val=4, steps_per_trial=1,\n",
    "                                              max_trials=3)\n",
    "wandb_logger.watch(model, log=\"all\", log_graph=False)\n",
    "\n",
    "# Load trained model\n",
    "plmodule_kwargs = {'model': model, \n",
    "                   'lr_info': lr_info, \n",
    "                   'trainer_options': trainer_options, \n",
    "                   'temporal_test_dataset_parameters': temporal_test_dataset_parameters}\n",
    "\n",
    "if 'saved_model' in config:\n",
    "    plmodule = LightningTrainer.load_from_checkpoint(\n",
    "        config['saved_model'],\n",
    "        map_location=device,\n",
    "        model=model,\n",
    "        lr_info=lr_info,\n",
    "        trainer_options=trainer_options,\n",
    "        temporal_test_dataset_parameters=temporal_test_dataset_parameters\n",
    "    )\n",
    "    # transfer model to device\n",
    "    plmodule.model = plmodule.model.to(device)\n",
    "  \n",
    "# Define trainer\n",
    "trainer = L.Trainer(accelerator=\"auto\", devices='auto',\n",
    "                    max_epochs=trainer_options['max_epochs'],\n",
    "                    gradient_clip_val=1, \n",
    "                    # log_every_n_steps=50,\n",
    "                    # enable_progress_bar=False,\n",
    "                    # accumulate_grad_batches=4,\n",
    "                    # profiler=\"simple\",\n",
    "                    precision='16-mixed',\n",
    "                    logger=wandb_logger,\n",
    "                    callbacks=[checkpoint_callback, \n",
    "                               curriculum_callback, \n",
    "                               early_stopping, \n",
    "                              #  batch_size_finder\n",
    "                               ])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Train and get trained model\n",
    "trainer.fit(plmodule, pldatamodule)\n",
    "\n",
    "# Load the best model checkpoint\n",
    "plmodule = LightningTrainer.load_from_checkpoint(\n",
    "    checkpoint_callback.best_model_path,\n",
    "    map_location=device,\n",
    "    model=model,\n",
    "    lr_info=lr_info,\n",
    "    trainer_options=trainer_options,\n",
    "    temporal_test_dataset_parameters=temporal_test_dataset_parameters\n",
    ")\n",
    "# transfer model to device\n",
    "plmodule.model = plmodule.model.to(device)\n",
    "\n",
    "model = plmodule.model"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "test_size = len(test_dataset)\n",
    "maximum_time = test_dataset[0].WD.shape[1]\n",
    "numerical_times = get_numerical_times(test_dataset_name+'_test', \n",
    "                test_size, temporal_res, maximum_time, \n",
    "                **temporal_test_dataset_parameters,\n",
    "                overview_file='database/overview.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "test_dataset = [data.to(device) for data in test_dataset]\n",
    "temporal_test_dataset = to_temporal_dataset(test_dataset, rollout_steps=-1, **temporal_test_dataset_parameters)\n",
    "\n",
    "test_dataloader = DataLoader(temporal_test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "start_time = time.time()\n",
    "predicted_rollout = trainer.predict(plmodule, dataloaders=test_dataloader)\n",
    "prediction_times = time.time() - start_time\n",
    "prediction_times = prediction_times/len(temporal_test_dataset)\n",
    "predicted_rollout = [item for roll in predicted_rollout for item in roll]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "spatial_analyser = SpatialAnalysis(predicted_rollout, prediction_times, \n",
    "                                   test_dataset, **temporal_test_dataset_parameters)\n",
    "\n",
    "rollout_loss = spatial_analyser._get_rollout_loss(type_loss='MAE', only_where_water=False)\n",
    "model_times = spatial_analyser.prediction_times\n",
    "\n",
    "avg_speedup, std_speedup = get_speed_up(numerical_times, model_times)\n",
    "print(f'mean speed-up: {avg_speedup:.2f}\\nstd speed-up: {std_speedup:.3f}')\n",
    "\n",
    "print('CSI 0.05m: ', spatial_analyser._get_CSI(water_threshold=0.05).mean().item())\n",
    "print('CSI 0.3m: ', spatial_analyser._get_CSI(water_threshold=0.3).nanmean().item())\n",
    "\n",
    "print('water depth error: ', rollout_loss.mean(0)[0].item())\n",
    "print('discharge error: ', rollout_loss.mean(0)[1:].item())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis (single simulation)\n",
    "Find the best and worst simulations in a given dataset\n",
    "\n",
    "Then, you can plot the simulation summaries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "sorted_ids = spatial_analyser.plot_loss_per_simulation(type_loss='RMSE', ranking='loss', only_where_water=False, water_thresholds=[0.05, 0.3])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "id_dataset = 5\n",
    "\n",
    "# # rotate sample to check invariance\n",
    "# angle = -135\n",
    "# test_dataset[id_dataset] = rotate_data_sample(test_dataset[id_dataset], angle, \n",
    "#                                               selected_node_features, selected_edge_features)\n",
    "\n",
    "rollout_plotter = PlotRollout(model.to(device), test_dataset[id_dataset].to(device), \n",
    "                              scalers=scalers, type_loss='RMSE', **temporal_test_dataset_parameters)\n",
    "\n",
    "rollout_plotter.plot_BC();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig = rollout_plotter.explore_rollout(time_step=-1, scale=0, logscale=True)\n",
    "# fig = rollout_plotter.explore_multiscale_rollout(time_step=-1, variable='V', logscale=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot WD and V for a single simulation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plot_times = [11, 23, 35]\n",
    "\n",
    "rollout_plotter.compare_h_rollout(plot_times, scale=0)\n",
    "rollout_plotter.compare_v_rollout(plot_times, scale=0, logscale=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare flood arrival times (FAT)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rollout_plotter.compare_FAT(water_threshold=0.05, scale=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rollout_plotter.mesh_scale_plot(scale=0)\n",
    "rollout_plotter.create_video(logscale=True)\n",
    "# rollout_plotter.save_video(f'results/SWEGNN_test_{id_dataset:02d}', fps=7)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boundary conditions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "spatial_analyser._plot_BCs();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial (F1 and CSI) and regression metrics for full dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mpl.rcParams['font.size'] = 18\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "_, CSI = spatial_analyser.plot_CSI_rollouts(water_thresholds=[0.05, 0.3], ax=axs[0])\n",
    "print(np.nanmean(CSI, 1).mean(1))\n",
    "\n",
    "# _, F1 = spatial_analyser.plot_F1_rollouts(water_thresholds=[0.05, 0.3], ax=axs[0])\n",
    "# print(np.nanmean(F1, 1).mean(1))\n",
    "\n",
    "_ = spatial_analyser._plot_rollouts(type_loss='MAE', ax=axs[1])\n",
    "\n",
    "axs[0].grid(False)\n",
    "\n",
    "plt.tight_layout()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mswe-gnn-venv",
   "language": "python",
   "name": "mswe-gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
