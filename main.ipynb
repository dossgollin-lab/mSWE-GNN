{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.visualization import *\n",
    "from utils.dataset import *\n",
    "from utils.miscellaneous import *\n",
    "from utils.load import *\n",
    "from utils.scaling import *\n",
    "from models.gnn import *\n",
    "from models.models import *\n",
    "from training.train import *\n",
    "from training.loss import *\n",
    "from database.graph_creation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worthy-firebrand-8</strong> at: <a href='https://wandb.ai/james-dossgollin-rice-university/mSWE-GNN/runs/4ypc2nqf' target=\"_blank\">https://wandb.ai/james-dossgollin-rice-university/mSWE-GNN/runs/4ypc2nqf</a><br> View project at: <a href='https://wandb.ai/james-dossgollin-rice-university/mSWE-GNN' target=\"_blank\">https://wandb.ai/james-dossgollin-rice-university/mSWE-GNN</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250716_105441-4ypc2nqf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/jamesdoss-gollin/Documents/mSWE-GNN/wandb/run-20250716_111220-wno6oi3z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/james-dossgollin-rice-university/mSWE-GNN/runs/wno6oi3z' target=\"_blank\">expert-mountain-9</a></strong> to <a href='https://wandb.ai/james-dossgollin-rice-university/mSWE-GNN' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/james-dossgollin-rice-university/mSWE-GNN' target=\"_blank\">https://wandb.ai/james-dossgollin-rice-university/mSWE-GNN</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/james-dossgollin-rice-university/mSWE-GNN/runs/wno6oi3z' target=\"_blank\">https://wandb.ai/james-dossgollin-rice-university/mSWE-GNN/runs/wno6oi3z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/james-dossgollin-rice-university/mSWE-GNN/runs/wno6oi3z?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x182251d50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['grid.color'] = 'k'\n",
    "mpl.rcParams['grid.linestyle'] = ':'\n",
    "mpl.rcParams['grid.linewidth'] = 0.5\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [7, 5]\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "mpl.rcParams['savefig.dpi'] = 300\n",
    "mpl.rcParams['savefig.bbox'] = 'tight'\n",
    "\n",
    "mpl.rcParams['font.size'] = 18\n",
    "mpl.rcParams['legend.fontsize'] = 'small'\n",
    "mpl.rcParams['figure.titlesize'] = 'small'\n",
    "\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "\n",
    "video_folder = figures_folder = 'results'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.login()\n",
    "\n",
    "# CHANGE THIS CONFIG FILE TO CHANGE THE EXPERIMENT\n",
    "cfg_file = \"config.yaml\"\n",
    "# cfg_file = \"config_finetune.yaml\"\n",
    "\n",
    "config = read_config(cfg_file)\n",
    "\n",
    "wandb_logger = WandbLogger(log_model='all',\n",
    "                           mode='online',\n",
    "                           config=config,)\n",
    "\n",
    "# Keep the original config structure since wandb.config might flatten it\n",
    "# config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 666\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'database/datasets/train/multiscale_mesh_dataset.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m selected_node_features = config[\u001b[33m'\u001b[39m\u001b[33mselected_node_features\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     12\u001b[39m selected_edge_features = config[\u001b[33m'\u001b[39m\u001b[33mselected_edge_features\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m train_dataset, val_dataset, test_dataset, scalers = \u001b[43mcreate_model_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscalers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscalers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdataset_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mselected_node_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mselected_edge_features\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mSWE-GNN/utils/dataset.py:320\u001b[39m, in \u001b[36mcreate_model_dataset\u001b[39m\u001b[34m(train_dataset_name, train_size, val_prcnt, test_dataset_name, dataset_folder, scalers, seed, device, **dataset_parameters)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[33;03mCreate dataset with scaled node and edge attributes\u001b[39;00m\n\u001b[32m    297\u001b[39m \u001b[33;03mReturn training, validation, and testing datasets\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    317\u001b[39m \u001b[33;03m        selects the desired time step for the temporal resolution\u001b[39;00m\n\u001b[32m    318\u001b[39m \u001b[33;03m'''\u001b[39;00m\n\u001b[32m    319\u001b[39m \u001b[38;5;66;03m# Load datasets\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m train_dataset = \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m test_dataset = load_dataset(test_dataset_name, \u001b[32m100\u001b[39m, seed=\u001b[32m0\u001b[39m, dataset_folder=os.path.join(dataset_folder, \u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m    322\u001b[39m \u001b[38;5;66;03m# create validation dataset from training\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/mSWE-GNN/utils/load.py:31\u001b[39m, in \u001b[36mload_dataset\u001b[39m\u001b[34m(dataset_name, size, seed, dataset_folder)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[33;03mLoads dataset, composed by a list of pytorch geometric data objects\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03m------\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m \u001b[33;03m    number of simulations selected\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03m'''\u001b[39;00m        \n\u001b[32m     29\u001b[39m path = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pkl\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m     32\u001b[39m     dataset = pickle.load(file)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m seed!=\u001b[32m0\u001b[39m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'database/datasets/train/multiscale_mesh_dataset.pkl'"
     ]
    }
   ],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "L.seed_everything(config['models']['seed'])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset_parameters = config['dataset_parameters']\n",
    "scalers = copy(config['scalers'])\n",
    "selected_node_features = config['selected_node_features']\n",
    "selected_edge_features = config['selected_edge_features']\n",
    "\n",
    "train_dataset, val_dataset, test_dataset, scalers = create_model_dataset(\n",
    "    scalers=scalers, device=device, \n",
    "    **dataset_parameters, **selected_node_features, **selected_edge_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temporal_dataset_parameters = config['temporal_dataset_parameters']\n",
    "\n",
    "temporal_train_dataset = to_temporal_dataset(train_dataset, **temporal_dataset_parameters)\n",
    "\n",
    "print('Number of training simulations:\\t', len(train_dataset))\n",
    "print('Number of training samples:\\t', len(temporal_train_dataset))\n",
    "print('Number of node features:\\t', temporal_train_dataset[0].x.shape[-1])\n",
    "print('Number of rollout steps:\\t', temporal_train_dataset[0].y.shape[-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_features, num_edge_features = temporal_train_dataset[0].x.size(-1), temporal_train_dataset[0].edge_attr.size(-1)\n",
    "num_nodes, num_edges = temporal_train_dataset[0].x.size(0), temporal_train_dataset[0].edge_attr.size(0)\n",
    "\n",
    "temporal_res = dataset_parameters['temporal_res']\n",
    "previous_t = temporal_dataset_parameters['previous_t']\n",
    "time_start = temporal_dataset_parameters['time_start']\n",
    "time_stop = temporal_dataset_parameters['time_stop']\n",
    "max_rollout_steps = temporal_dataset_parameters['rollout_steps']\n",
    "test_dataset_name = dataset_parameters['test_dataset_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = copy(config['models'])\n",
    "model_type = model_parameters.pop('model_type')\n",
    "\n",
    "if model_type == 'MSGNN':\n",
    "    num_scales = train_dataset[0].mesh.num_meshes\n",
    "    model_parameters['num_scales'] = num_scales\n",
    "    \n",
    "model = get_model(model_type)(\n",
    "    num_node_features=num_node_features,\n",
    "    num_edge_features=num_edge_features,\n",
    "    previous_t=previous_t,\n",
    "    device=device,\n",
    "    **model_parameters).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer_options = copy(config['trainer_options'])\n",
    "\n",
    "lr_info = config['lr_info']\n",
    "\n",
    "# info for testing dataset\n",
    "temporal_test_dataset_parameters = get_temporal_test_dataset_parameters(\n",
    "    config, temporal_dataset_parameters)\n",
    "\n",
    "temporal_val_dataset = to_temporal_dataset(val_dataset, rollout_steps=-1, **temporal_test_dataset_parameters)\n",
    "\n",
    "plmodule = LightningTrainer(model, lr_info, trainer_options, temporal_test_dataset_parameters).to(device)\n",
    "\n",
    "pldatamodule = DataModule(temporal_train_dataset, temporal_val_dataset, \n",
    "                          batch_size=trainer_options['batch_size'])\n",
    "\n",
    "print(\"Total number of paramters:\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "checkpoint_callback = ModelCheckpoint(dirpath='lightning_logs/models',\n",
    "                                      monitor=\"val_loss\", mode='min',\n",
    "                                      save_top_k=1)\n",
    "curriculum_callback = CurriculumLearning(max_rollout_steps, patience=5)\n",
    "early_stopping      = EarlyStopping('val_CSI_005', mode='max', patience=trainer_options['patience'])\n",
    "batch_size_finder   = CurriculumBatchSizeFinder(max_rollout_steps, init_val=4, steps_per_trial=1,\n",
    "                                              max_trials=3)\n",
    "wandb_logger.watch(model, log=\"all\", log_graph=False)\n",
    "\n",
    "# Load trained model\n",
    "plmodule_kwargs = {'model': model, \n",
    "                   'lr_info': lr_info, \n",
    "                   'trainer_options': trainer_options, \n",
    "                   'temporal_test_dataset_parameters': temporal_test_dataset_parameters}\n",
    "\n",
    "if 'saved_model' in config:\n",
    "  model = plmodule.load_from_checkpoint(config['saved_model'], map_location=device, **plmodule_kwargs)\n",
    "  model = plmodule.model.to(device)\n",
    "  \n",
    "# Define trainer\n",
    "trainer = L.Trainer(accelerator=\"auto\", devices='auto',\n",
    "                    max_epochs=trainer_options['max_epochs'],\n",
    "                    gradient_clip_val=1, \n",
    "                    # log_every_n_steps=50,\n",
    "                    # enable_progress_bar=False,\n",
    "                    # accumulate_grad_batches=4,\n",
    "                    # profiler=\"simple\",\n",
    "                    precision='16-mixed',\n",
    "                    logger=wandb_logger,\n",
    "                    callbacks=[checkpoint_callback, \n",
    "                               curriculum_callback, \n",
    "                               early_stopping, \n",
    "                              #  batch_size_finder\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and get trained model\n",
    "trainer.fit(plmodule, pldatamodule)\n",
    "\n",
    "# Load the best model checkpoint\n",
    "plmodule.model = plmodule.load_from_checkpoint(checkpoint_callback.best_model_path, map_location=device, **plmodule_kwargs).model.to(device)\n",
    "\n",
    "model = plmodule.model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = len(test_dataset)\n",
    "maximum_time = test_dataset[0].WD.shape[1]\n",
    "numerical_times = get_numerical_times(test_dataset_name+'_test', \n",
    "                test_size, temporal_res, maximum_time, \n",
    "                **temporal_test_dataset_parameters,\n",
    "                overview_file='database/overview.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = [data.to(device) for data in test_dataset]\n",
    "temporal_test_dataset = to_temporal_dataset(test_dataset, rollout_steps=-1, **temporal_test_dataset_parameters)\n",
    "\n",
    "test_dataloader = DataLoader(temporal_test_dataset, batch_size=10, shuffle=False)\n",
    "\n",
    "start_time = time.time()\n",
    "predicted_rollout = trainer.predict(plmodule, dataloaders=test_dataloader)\n",
    "prediction_times = time.time() - start_time\n",
    "prediction_times = prediction_times/len(temporal_test_dataset)\n",
    "predicted_rollout = [item for roll in predicted_rollout for item in roll]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_analyser = SpatialAnalysis(predicted_rollout, prediction_times, \n",
    "                                   test_dataset, **temporal_test_dataset_parameters)\n",
    "\n",
    "rollout_loss = spatial_analyser._get_rollout_loss(type_loss='MAE', only_where_water=False)\n",
    "model_times = spatial_analyser.prediction_times\n",
    "\n",
    "avg_speedup, std_speedup = get_speed_up(numerical_times, model_times)\n",
    "print(f'mean speed-up: {avg_speedup:.2f}\\nstd speed-up: {std_speedup:.3f}')\n",
    "\n",
    "print('CSI 0.05m: ', spatial_analyser._get_CSI(water_threshold=0.05).mean().item())\n",
    "print('CSI 0.3m: ', spatial_analyser._get_CSI(water_threshold=0.3).nanmean().item())\n",
    "\n",
    "print('water depth error: ', rollout_loss.mean(0)[0].item())\n",
    "print('discharge error: ', rollout_loss.mean(0)[1:].item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis (single simulation)\n",
    "Find the best and worst simulations in a given dataset\n",
    "\n",
    "Then, you can plot the simulation summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ids = spatial_analyser.plot_loss_per_simulation(type_loss='RMSE', ranking='loss', only_where_water=False, water_thresholds=[0.05, 0.3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dataset = 5\n",
    "\n",
    "# # rotate sample to check invariance\n",
    "# angle = -135\n",
    "# test_dataset[id_dataset] = rotate_data_sample(test_dataset[id_dataset], angle, \n",
    "#                                               selected_node_features, selected_edge_features)\n",
    "\n",
    "rollout_plotter = PlotRollout(model.to(device), test_dataset[id_dataset].to(device), \n",
    "                              scalers=scalers, type_loss='RMSE', **temporal_test_dataset_parameters)\n",
    "\n",
    "rollout_plotter.plot_BC();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = rollout_plotter.explore_rollout(time_step=-1, scale=0, logscale=True)\n",
    "# fig = rollout_plotter.explore_multiscale_rollout(time_step=-1, variable='V', logscale=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot WD and V for a single simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_times = [11, 23, 35]\n",
    "\n",
    "rollout_plotter.compare_h_rollout(plot_times, scale=0)\n",
    "rollout_plotter.compare_v_rollout(plot_times, scale=0, logscale=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare flood arrival times (FAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_plotter.compare_FAT(water_threshold=0.05, scale=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_plotter.mesh_scale_plot(scale=0)\n",
    "rollout_plotter.create_video(logscale=True)\n",
    "# rollout_plotter.save_video(f'results/SWEGNN_test_{id_dataset:02d}', fps=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boundary conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_analyser._plot_BCs();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial (F1 and CSI) and regression metrics for full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['font.size'] = 18\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "_, CSI = spatial_analyser.plot_CSI_rollouts(water_thresholds=[0.05, 0.3], ax=axs[0])\n",
    "print(np.nanmean(CSI, 1).mean(1))\n",
    "\n",
    "# _, F1 = spatial_analyser.plot_F1_rollouts(water_thresholds=[0.05, 0.3], ax=axs[0])\n",
    "# print(np.nanmean(F1, 1).mean(1))\n",
    "\n",
    "_ = spatial_analyser._plot_rollouts(type_loss='MAE', ax=axs[1])\n",
    "\n",
    "axs[0].grid(False)\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mswe-gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
